# {{cookiecutter.project_name}} Backend

{{cookiecutter.description}}

A clean, simple FastAPI backend with LangChain integration for LLM-powered applications.

## âœ¨ Features

### Core Features
- **ğŸš€ FastAPI**: Modern, fast web framework for building APIs
- **ğŸ” Clerk Authentication**: Enterprise-grade authentication with JWT
- **ğŸ—„ï¸ Database**: SQLAlchemy async with PostgreSQL/SQLite support
- **ğŸ”— LangChain Integration**: OpenRouter provider for LLM access
- **ğŸ¤– Agents Framework**: Modular agent structure with prompts, tools, and structured outputs
- **ğŸ“Š Health & Metrics**: Simple health checks and metrics endpoints
- **ğŸ“ Structured Logging**: Request tracing and logging utilities

### LangChain & LLM Features
- **OpenRouter Provider**: Unified access to multiple LLM providers
- **Token Counting**: Accurate token counting utilities
- **Agent Framework**: Modular agent structure (agents/prompt/tool/structured_output)
- **Context Management**: Built-in context management agent
- **Tool Support**: LangChain tools for agent workflows

## ğŸ—ï¸ Architecture

```
app/
â”œâ”€â”€ main.py                    # FastAPI application entry point
â”œâ”€â”€ config.py                  # Simple configuration (no env-specific complexity)
â”œâ”€â”€ dependencies.py            # Dependency injection
â”œâ”€â”€ exceptions.py              # Exception handlers
â”‚
â”œâ”€â”€ api/                       # API endpoints
â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”œâ”€â”€ router.py         # Main API router
â”‚   â”‚   â”œâ”€â”€ auth.py           # Clerk authentication endpoints
â”‚   â”‚   â”œâ”€â”€ health.py         # Health check endpoints
â”‚   â”‚   â””â”€â”€ metrics.py        # Metrics endpoints
â”‚   â””â”€â”€ deps.py               # API-specific dependencies
â”‚
â”œâ”€â”€ agents/                    # LangChain agents framework
â”‚   â”œâ”€â”€ agents/               # Agent implementations
â”‚   â”‚   â””â”€â”€ context_manager.py
â”‚   â”œâ”€â”€ prompt/               # Prompt templates
â”‚   â”‚   â””â”€â”€ context_manager.py
â”‚   â”œâ”€â”€ tool/                 # LangChain tools
â”‚   â”‚   â””â”€â”€ context_manager.py
â”‚   â””â”€â”€ structured_output/    # Pydantic output models
â”‚       â””â”€â”€ context_manager.py
â”‚
â”œâ”€â”€ database/                  # Database layer
â”‚   â”œâ”€â”€ base.py               # SQLAlchemy base
â”‚   â”œâ”€â”€ session.py            # Async session management
â”‚   â”œâ”€â”€ models/               # Database models
â”‚   â”‚   â””â”€â”€ user.py           # User model (only model)
â”‚   â””â”€â”€ repositories/         # Data access layer
â”‚       â””â”€â”€ user.py           # User repository (only repository)
â”‚
â”œâ”€â”€ infrastructure/            # Infrastructure layer
â”‚   â””â”€â”€ llm_provider.py       # OpenRouter LLM provider
â”‚
â”œâ”€â”€ models/                    # Pydantic API models
â”‚   â”œâ”€â”€ base.py               # Base response models
â”‚   â””â”€â”€ user.py               # User API models
â”‚
â”œâ”€â”€ security/                  # Security utilities
â”‚   â””â”€â”€ clerk_auth.py         # Clerk authentication
â”‚
â”œâ”€â”€ middleware/                # Middleware
â”‚   â””â”€â”€ __init__.py           # Logging, CORS, security headers
â”‚
â”œâ”€â”€ utils/                     # Utilities
â”‚   â”œâ”€â”€ logging.py            # Logging configuration
â”‚   â””â”€â”€ token_counter.py      # Token counting utilities
â”‚
â””â”€â”€ examples/                  # Example code
    â”œâ”€â”€ langchain_example.py  # LangChain usage examples
    â”œâ”€â”€ agent_example.py      # Agent usage examples
    â””â”€â”€ tool_example.py       # Tool usage examples
```

## ğŸš€ Quick Start

### Prerequisites

- **Python**: {{cookiecutter.python_version}}+
- **OpenRouter API Key**: Get one at https://openrouter.ai
- **Clerk Account**: Get one at https://clerk.dev (optional, for auth)

### 1. Configuration Setup

```bash
# Copy the configuration template
cp .env.template .env

# Edit your configuration
nano .env  # or use your preferred editor
```

**Required Settings:**

```bash
# OpenRouter API Key (required for LLM features)
OPENROUTER_API_KEY=your-openrouter-api-key-here

# Database (SQLite by default)
DATABASE_URL=sqlite+aiosqlite:///./app.db

# Clerk Authentication (optional)
CLERK_SECRET_KEY=sk_test_...
CLERK_PUBLISHABLE_KEY=pk_test_...
```

### 2. Install Dependencies

```bash
# Using uv (recommended)
curl -LsSf https://astral.sh/uv/install.sh | sh
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -e .

# Or using pip
pip install -e .
```

### 3. Database Setup

```bash
# Run migrations
alembic upgrade head

# Or initialize database
python -m app.cli database init
```

### 4. Start the Server

```bash
# Development server
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# Or using Python directly
python -m app.main
```

### 5. Access the Application

| Service | URL | Description |
|---------|-----|-------------|
| **ğŸš€ Backend API** | http://localhost:8000 | Main API server |
| **ğŸ“š API Documentation** | http://localhost:8000/docs | Interactive Swagger UI |
| **ğŸ¥ Health Checks** | http://localhost:8000/api/v1/health/ | Service health monitoring |

## ğŸ“¡ API Usage

### Health Checks

```bash
# Main health check
curl "http://localhost:8000/api/v1/health/"

# Database health
curl "http://localhost:8000/api/v1/health/database"

# Readiness probe
curl "http://localhost:8000/api/v1/health/ready"

# Liveness probe
curl "http://localhost:8000/api/v1/health/live"
```

### Authentication (Clerk)

```bash
# Get current user profile
curl -X GET "http://localhost:8000/api/v1/auth/profile" \
  -H "Authorization: Bearer YOUR_CLERK_JWT_TOKEN"

# Check Clerk configuration
curl "http://localhost:8000/api/v1/auth/config"
```

## ğŸ¤– LangChain & Agents Usage

### Basic LangChain Example

```python
from app.infrastructure.llm_provider import OpenRouterProvider
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# Initialize provider
provider = OpenRouterProvider()

# Get LLM instance
llm = provider.get_llm(model_name="openai/gpt-4o-mini", temperature=0.7)

# Create chain
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant."),
    ("user", "{input}")
])

chain = prompt | llm | StrOutputParser()

# Use chain
response = chain.invoke({"input": "Hello!"})
print(response)
```

### Using Agents

```python
from app.agents.agents.context_manager import ContextManagerAgent, ContextCheckRequest
from app.infrastructure.llm_provider import OpenRouterProvider

# Initialize
provider = OpenRouterProvider()
agent = ContextManagerAgent(provider, model_name="openai/gpt-4o-mini")

# Check context
request = ContextCheckRequest(
    system_prompt="You are a helpful assistant.",
    history=[{"role": "user", "content": "Hello"}],
    current_item="New message",
    model_name="openai/gpt-4o-mini"
)

result = agent.check_context(request)
print(f"Total tokens: {result.total_tokens}")
print(f"Exceeds limit: {result.exceeds_limit}")
```

### Using Tools

```python
from app.agents.tool.context_manager import count_history_items, get_recent_items

# Use tools directly
history = [{"role": "user", "content": "Hello"}]
count = count_history_items.invoke({"history": history})

# Bind tools to LLM
from app.infrastructure.llm_provider import OpenRouterProvider

provider = OpenRouterProvider()
llm = provider.get_llm(model_name="openai/gpt-4o-mini")
llm_with_tools = llm.bind_tools([count_history_items, get_recent_items])

# LLM can now use these tools
response = llm_with_tools.invoke("Count items in my history")
```

### Token Counting

```python
from app.infrastructure.llm_provider import OpenRouterProvider
from app.utils.token_counter import count_tokens_llm, get_model_limits

provider = OpenRouterProvider()
llm = provider.get_llm(model_name="openai/gpt-4o-mini")

# Count tokens
text = "Hello, how are you?"
token_count = count_tokens_llm(llm, text)

# Get model limits
limits = get_model_limits(provider, "openai/gpt-4o-mini")
print(f"Context length: {limits['context_length']}")
print(f"Max completion: {limits['max_completion_tokens']}")
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/unit/test_auth.py

# Run integration tests
pytest tests/integration/
```

## ğŸ“š Examples

Check out the example files in `app/examples/`:

- **`langchain_example.py`**: Basic LangChain usage
- **`agent_example.py`**: Using agents
- **`tool_example.py`**: Using LangChain tools

Run examples:
```bash
python -m app.examples.langchain_example
python -m app.examples.agent_example
python -m app.examples.tool_example
```

## ğŸ”§ Configuration

All configuration is managed through environment variables. See `.env.template` for all available options.

### Key Settings

```bash
# Database
DATABASE_URL=sqlite+aiosqlite:///./app.db

# API Server
API_HOST=0.0.0.0
API_PORT=8000

# OpenRouter (for LLM)
OPENROUTER_API_KEY=your-key-here

# Clerk Authentication
CLERK_SECRET_KEY=sk_test_...
CLERK_PUBLISHABLE_KEY=pk_test_...

# Logging
LOG_LEVEL=INFO
DEBUG=false
```

## ğŸ—ï¸ Project Structure

### Agents Framework

The agents follow a modular structure:

```
agents/
â”œâ”€â”€ agents/              # Agent implementations
â”œâ”€â”€ prompt/              # Prompt templates
â”œâ”€â”€ tool/                # LangChain tools
â””â”€â”€ structured_output/   # Pydantic output models
```

Each agent has:
- **Agent**: Business logic implementation
- **Prompts**: System and user prompts
- **Tools**: LangChain tools the agent can use
- **Structured Outputs**: Type-safe Pydantic models

See `app/agents/README.md` for more details.

### Database

- **Models**: Only `User` model
- **Repositories**: Only `UserRepository`
- **Async**: Full async/await support

### Infrastructure

- **LLM Provider**: OpenRouter integration
- **Token Counter**: Token counting utilities
- **Model Info**: Context limits and model information

## ğŸ”’ Security

- **Clerk Authentication**: JWT-based authentication
- **CORS**: Configurable CORS settings
- **Security Headers**: Automatic security headers
- **Input Validation**: Pydantic validation

## ğŸ“Š Monitoring

- **Health Checks**: `/api/v1/health/`
- **Metrics**: `/api/v1/metrics/`
- **Structured Logging**: Request tracing with correlation IDs

## ğŸš€ Production Deployment

### Docker

```bash
# Build image
docker build -t {{cookiecutter.project_slug}}-backend .

# Run container
docker run -p 8000:8000 \
  -e OPENROUTER_API_KEY=your-key \
  -e DATABASE_URL=postgresql://... \
  {{cookiecutter.project_slug}}-backend
```

### Environment Variables

Required:
- `OPENROUTER_API_KEY`: OpenRouter API key
- `DATABASE_URL`: Database connection string

Optional:
- `CLERK_SECRET_KEY`: Clerk secret key
- `CLERK_PUBLISHABLE_KEY`: Clerk publishable key
- `DEBUG`: Set to `false` in production
- `LOG_LEVEL`: Logging level (INFO, WARNING, ERROR)

## ğŸ› Troubleshooting

### Common Issues

**OpenRouter API Key not set:**
```bash
# Set in .env file
OPENROUTER_API_KEY=your-key-here
```

**Database connection issues:**
```bash
# Check database URL
echo $DATABASE_URL

# Test connection
python -c "from app.database.session import get_async_engine; import asyncio; asyncio.run(get_async_engine())"
```

**Import errors:**
```bash
# Make sure you're in the backend directory
cd backend

# Install dependencies
uv pip install -e .
```

## ğŸ“š Additional Resources

- **API Documentation**: http://localhost:8000/docs
- **Agents README**: `app/agents/README.md`
- **LangChain Docs**: https://python.langchain.com/

## ğŸ“„ License

MIT License

---

**Generated by [cookiecutter-fastapi-nextjs-llm](https://github.com/your-org/cookiecutter-fastapi-nextjs-llm)**
